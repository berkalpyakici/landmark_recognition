{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir=\"C:\\Users\\Mason\\Downloads\\Kaggle\\Google Landmark Classification 2020\\Data\\landmark-recognition-2020\"\n",
    "#model_dir=./weights\n",
    "\n",
    "Preprocessing = python Scripts/preprocessing.py --data-dir Data/landmark-recognition-2020\n",
    "\n",
    "### B7 \n",
    "\n",
    "python -u Scripts/train.py --kernel-type b7ns_final_64_300w_f0_20ep --train-step 0 --data-dir Data/landmark-recognition-2020 --image-size 64 --batch-size 42 --enet-type tf_efficientnet_b7_ns --n-epochs 20 --CUDA_VISIBLE_DEVICES 0 --fold 0 --local_rank 0\n",
    "\n",
    "python -u Scripts/train.py --kernel-type b7ns_final_16_300w_f0_2ep --train-step 0 --data-dir Data/landmark-recognition-2020 --image-size 16 --batch-size 42 --enet-type tf_efficientnet_b7_ns --n-epochs 2 --CUDA_VISIBLE_DEVICES 0 --fold 0 --local_rank 0\n",
    "\n",
    "# python -u -m torch.distributed.launch --nproc_per_node=8 train.py --kernel-type b7ns_DDP_final_512_300w_f0_40ep --train-step 1 --data-dir ${data_dir} --image-size 512 --batch-size 16 --enet-type tf_efficientnet_b7_ns --n-epochs 40 --stop-at-epoch 13 --fold 0 --load-from ${model_dir}/b7ns_DDP_final_256_300w_f0_10ep_fold0.pth\n",
    "\n",
    "# python -u -m torch.distributed.launch --nproc_per_node=8 train.py --kernel-type b7ns_final_672_300w_f0_load13_ep20 --train-step 2 --data-dir ${data_dir} --init-lr 5e-5 --image-size 672 --batch-size 10 --enet-type tf_efficientnet_b7_ns --n-epochs 20 --stop-at-epoch 1 --fold 0 --load-from ${model_dir}/b7ns_DDP_final_512_300w_f0_40ep_fold0.pth\n",
    "\n",
    "# python -u -m torch.distributed.launch --nproc_per_node=8 train.py --kernel-type b7ns_final_672_300w_f0_load13_load1_14ep --train-step 3 --data-dir ${data_dir} --image-size 672 --batch-size 10 --enet-type tf_efficientnet_b7_ns --n-epochs 14 --stop-at-epoch 4 --fold 0 --load-from ${model_dir}/b7ns_final_672_300w_f0_load13_ep20_fold0.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd Downloads/Kaggle/landmark/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_dir = \"C:/Users/Mason/Downloads/Kaggle/landmark/Data/landmark-recognition-2020\"\n",
    "\n",
    "df = pd.read_csv(f\"{data_dir}/train_kaggle.csv\")\n",
    "# print(df.shape)\n",
    "\n",
    "# df['exists'] = df['id'].apply(lambda x: os.path.exists(os.path.join(data_dir, 'train', \"0\", x[1], x[2], f'{x}.jpg')))\n",
    "\n",
    "# print(df[df['exists']].shape)\n",
    "subset = df[df[\"id\"].str.startswith(\"0\")]\n",
    "subset.to_csv(f\"{data_dir}/train_subset_0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{data_dir}/train_subset_0.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "## Get Id of default device\n",
    "torch.cuda.current_device()\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def filter_train_by_threshold(threshold):\n",
    "  df = pd.read_csv('Data/landmark-recognition-2020/train.csv')\n",
    "  num_imgs = df['landmark_id'].value_counts().to_frame()\n",
    "\n",
    "  #print(num_imgs)\n",
    "  num_imgs_index = num_imgs.reset_index()\n",
    "  num_imgs_index.columns = ['landmark_id', 'count']\n",
    "\n",
    "  df_w_counts = df.merge(num_imgs_index, on='landmark_id',how='left')\n",
    "  filtered_data = df_w_counts[df_w_counts['count'] >= threshold]\n",
    "\n",
    "  filtered_data.to_csv('Data/landmark-recognition-2020/train_filtered_' + str(threshold) + '.csv', index=False)\n",
    "\n",
    "filter_train_by_threshold(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}